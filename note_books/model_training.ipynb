{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f89be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb200fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a2972",
   "metadata": {},
   "source": [
    "# Utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07768164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_outliers(df, column_names):\n",
    "    \"\"\"\n",
    "    Analyze and print the outlier rows for the given numeric columns using the IQR method.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "    column_names (list of str): List of numeric column names to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None (prints the outliers directly).\n",
    "    \"\"\"\n",
    "\n",
    "    df_analyze = df.copy()\n",
    "\n",
    "    for column in column_names:\n",
    "        # Define lower and upper bound\n",
    "        Q1 = df_analyze[column].quantile(0.25)\n",
    "        Q3 = df_analyze[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Select outliers\n",
    "        outliers = df_analyze[(df_analyze[column] < lower_bound) | (df_analyze[column] > upper_bound)]\n",
    "\n",
    "        # Print output\n",
    "        print(f\"Outliers for column '{column}':\")\n",
    "        if outliers.empty:\n",
    "            print(\"No outliers found.\")\n",
    "        else:\n",
    "            print(outliers[[column]])  # Prints only the column; add more columns if needed\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Example usage (assuming 'df' is your DataFrame):\n",
    "# analyze_outliers(df, ['MonthlyCharges', 'tenure', 'TotalCharges'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c9d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column_names):\n",
    "    \"\"\"\n",
    "    Remove outliers in numeric columns of the dataframe by using IQR method\n",
    "    outliers defined as laying outside 1.5 IQR lower or upper than Q1 & Q3\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    for column in column_names:\n",
    "        # define lower and upper bound\n",
    "        Q1 = df_clean[column].quantile(0.25)\n",
    "        Q3 = df_clean[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5*IQR\n",
    "        upper_bound = Q3 + 1.5*IQR\n",
    "\n",
    "        # filter out outliers\n",
    "        df_clean = df_clean[(df_clean[column] >= lower_bound) & (df_clean[column] <= upper_bound)]\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe8d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_outliers(df, column_names, limits = [0.05, 0.05]):\n",
    "    \"\"\"\n",
    "    instead of completely remove the extreme values of the dataset,\n",
    "    winsorize the outliers to cap the max values at 0.05 and 0.95\n",
    "\n",
    "    variables:\n",
    "    - columns_names: provide a list of column names\n",
    "    \"\"\"\n",
    "    df_winsorize = df.copy()\n",
    "\n",
    "    for column in column_names:\n",
    "        df_winsorize[column] = stats.mstats.winsorize(\n",
    "            df_winsorize[column],\n",
    "            limits = limits\n",
    "        )\n",
    "\n",
    "    return df_winsorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49350b9e",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f245bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/customer_churn_telecom_services.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cda452a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   gender            7043 non-null   object \n",
      " 1   SeniorCitizen     7043 non-null   int64  \n",
      " 2   Partner           7043 non-null   object \n",
      " 3   Dependents        7043 non-null   object \n",
      " 4   tenure            7043 non-null   int64  \n",
      " 5   PhoneService      7043 non-null   object \n",
      " 6   MultipleLines     7043 non-null   object \n",
      " 7   InternetService   7043 non-null   object \n",
      " 8   OnlineSecurity    7043 non-null   object \n",
      " 9   OnlineBackup      7043 non-null   object \n",
      " 10  DeviceProtection  7043 non-null   object \n",
      " 11  TechSupport       7043 non-null   object \n",
      " 12  StreamingTV       7043 non-null   object \n",
      " 13  StreamingMovies   7043 non-null   object \n",
      " 14  Contract          7043 non-null   object \n",
      " 15  PaperlessBilling  7043 non-null   object \n",
      " 16  PaymentMethod     7043 non-null   object \n",
      " 17  MonthlyCharges    7043 non-null   float64\n",
      " 18  TotalCharges      7032 non-null   float64\n",
      " 19  Churn             7043 non-null   object \n",
      "dtypes: float64(2), int64(2), object(16)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f7d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the missing data in 'TotalCharges'ArithmeticError# fill missing values in 'TotalCharges'\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['MonthlyCharges'] * df['tenure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1b22bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
       "       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
       "       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
       "       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod',\n",
       "       'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a427eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target and variables\n",
    "categorical_variable = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "numeric_variables = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "variables = df[categorical_variable + numeric_variables]\n",
    "\n",
    "target = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68306311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation test split of the dataset\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(variables, target, test_size = 0.2, random_state = 42, stratify = target)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.25, random_state = 42, stratify = y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "633fc1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder for target \n",
    "le = LabelEncoder()\n",
    "y_train_en = le.fit_transform(y_train)\n",
    "y_val_en = le.transform(y_val)\n",
    "y_test_en = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03384d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical encoding\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', drop = 'first')\n",
    "X_train_ohe = pd.DataFrame(ohe.fit_transform(X_train[categorical_variable]).toarray(), columns = ohe.get_feature_names_out(), index = X_train.index)\n",
    "X_val_ohe = pd.DataFrame(ohe.fit_transform(X_val[categorical_variable]).toarray(), columns = ohe.get_feature_names_out(), index = X_val.index)\n",
    "X_test_ohe = pd.DataFrame(ohe.fit_transform(X_test[categorical_variable]).toarray(), columns = ohe.get_feature_names_out(), index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "737817ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine nueric and encoded variables\n",
    "X_train = pd.concat([X_train[numeric_variables], X_train_ohe], axis = 1)\n",
    "X_val = pd.concat([X_val[numeric_variables], X_val_ohe], axis = 1)\n",
    "X_test = pd.concat([X_train[numeric_variables], X_train_ohe], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a160e520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers for column 'tenure':\n",
      "No outliers found.\n",
      "--------------------------------------------------\n",
      "Outliers for column 'MonthlyCharges':\n",
      "No outliers found.\n",
      "--------------------------------------------------\n",
      "Outliers for column 'TotalCharges':\n",
      "No outliers found.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# identify outliers\n",
    "analyze_outliers(X_train, numeric_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee0654",
   "metadata": {},
   "source": [
    "Since there is no outlier, we do not need to remove or winsorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92fd3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data with standardscaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train[numeric_variables] = scaler.fit_transform(X_train[numeric_variables])\n",
    "X_val[numeric_variables] = scaler.transform(X_val[numeric_variables])\n",
    "X_test[numeric_variables] = scaler.transform(X_test[numeric_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab29cdeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1409, 4225]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m y_val_pred = best_model.predict(X_val)\n\u001b[32m     23\u001b[39m y_test_pred = best_model.predict(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTest AUC-ROC:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_en\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test_en, y_test_pred))\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# SHAP explanations\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:686\u001b[39m, in \u001b[36mroc_auc_score\u001b[39m\u001b[34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[39m\n\u001b[32m    684\u001b[39m     labels = np.unique(y_true)\n\u001b[32m    685\u001b[39m     y_true = label_binarize(y_true, classes=labels)[:, \u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[32m    695\u001b[39m         partial(_binary_roc_auc_score, max_fpr=max_fpr),\n\u001b[32m    696\u001b[39m         y_true,\n\u001b[32m   (...)\u001b[39m\u001b[32m    699\u001b[39m         sample_weight=sample_weight,\n\u001b[32m    700\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/metrics/_base.py:69\u001b[39m, in \u001b[36m_average_binary_score\u001b[39m\u001b[34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[39m\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[32m     72\u001b[39m y_true = check_array(y_true)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:433\u001b[39m, in \u001b[36m_binary_roc_auc_score\u001b[39m\u001b[34m(y_true, y_score, sample_weight, max_fpr)\u001b[39m\n\u001b[32m    424\u001b[39m     warnings.warn(\n\u001b[32m    425\u001b[39m         (\n\u001b[32m    426\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOnly one class is present in y_true. ROC AUC score \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    429\u001b[39m         UndefinedMetricWarning,\n\u001b[32m    430\u001b[39m     )\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m fpr, tpr, _ = \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr == \u001b[32m1\u001b[39m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:1163\u001b[39m, in \u001b[36mroc_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[39m\n\u001b[32m   1059\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1060\u001b[39m     {\n\u001b[32m   1061\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1070\u001b[39m     y_true, y_score, *, pos_label=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1071\u001b[39m ):\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[32m   1073\u001b[39m \n\u001b[32m   1074\u001b[39m \u001b[33;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m \u001b[33;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[32m   1162\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m     fps, tps, thresholds = \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[32m   1169\u001b[39m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1174\u001b[39m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[32m   1176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) > \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:865\u001b[39m, in \u001b[36m_binary_clf_curve\u001b[39m\u001b[34m(y_true, y_score, pos_label, sample_weight)\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[32m    863\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m format is not supported\u001b[39m\u001b[33m\"\u001b[39m.format(y_type))\n\u001b[32m--> \u001b[39m\u001b[32m865\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m y_true = column_or_1d(y_true)\n\u001b[32m    867\u001b[39m y_score = column_or_1d(y_score)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/telco_churn/lib/python3.11/site-packages/sklearn/utils/validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [1409, 4225]"
     ]
    }
   ],
   "source": [
    "# Imbalance handling\n",
    "scale_pos_weight = sum(y_train_en == 0) / sum(y_train_en == 1)\n",
    "\n",
    "# Base model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    eval_metric='aucpr'\n",
    ")\n",
    "\n",
    "# Hyperparameter tuning on val (simple grid; expand as needed)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train_en)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print(\"Test AUC-ROC:\", roc_auc_score(y_test_en, y_test_pred))\n",
    "print(classification_report(y_test_en, y_test_pred))\n",
    "\n",
    "# SHAP explanations\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca745e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telco_churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
