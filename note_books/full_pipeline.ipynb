{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc03ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import roc_auc_score, classification_report, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_experiment(\"Telco Churn Multi-Model\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855d268",
   "metadata": {},
   "source": [
    "# utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437b6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    this function preprocess the data by taking in the original file path\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Fill missing in TotalCharges\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')  # Ensure numeric\n",
    "    df['TotalCharges'] = df['TotalCharges'].fillna(df['MonthlyCharges'] * df['tenure'])\n",
    "    \n",
    "    categorical_variables = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', \n",
    "                             'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                             'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n",
    "                             'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "    numeric_variables = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "    \n",
    "    variables = df[categorical_variables + numeric_variables]\n",
    "    target = df['Churn']\n",
    "    \n",
    "    # Train-val-test split\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        variables, target, test_size=0.2, random_state=42, stratify=target\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    # Label encode target\n",
    "    le = LabelEncoder()\n",
    "    y_train_en = le.fit_transform(y_train)\n",
    "    y_val_en = le.transform(y_val)\n",
    "    y_test_en = le.transform(y_test)\n",
    "    \n",
    "    # One-hot encode categoricals\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    X_train_ohe = pd.DataFrame(\n",
    "        ohe.fit_transform(X_train[categorical_variables]).toarray(), \n",
    "        columns=ohe.get_feature_names_out(), index=X_train.index\n",
    "    )\n",
    "    X_val_ohe = pd.DataFrame(\n",
    "        ohe.transform(X_val[categorical_variables]).toarray(), \n",
    "        columns=ohe.get_feature_names_out(), index=X_val.index\n",
    "    )\n",
    "    X_test_ohe = pd.DataFrame(\n",
    "        ohe.transform(X_test[categorical_variables]).toarray(), \n",
    "        columns=ohe.get_feature_names_out(), index=X_test.index\n",
    "    )\n",
    "    \n",
    "    # Combine numeric and encoded\n",
    "    X_train = pd.concat([X_train[numeric_variables], X_train_ohe], axis=1)\n",
    "    X_val = pd.concat([X_val[numeric_variables], X_val_ohe], axis=1)\n",
    "    X_test = pd.concat([X_test[numeric_variables], X_test_ohe], axis=1)\n",
    "    \n",
    "    # Scale numerics\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numeric_variables] = scaler.fit_transform(X_train[numeric_variables])\n",
    "    X_val[numeric_variables] = scaler.transform(X_val[numeric_variables])\n",
    "    X_test[numeric_variables] = scaler.transform(X_test[numeric_variables])\n",
    "    \n",
    "    # Imbalance handling: Compute scale_pos_weight\n",
    "    scale_pos_weight = sum(y_train_en == 0) / sum(y_train_en == 1)\n",
    "    \n",
    "    # Log data info as artifact\n",
    "    with open(\"data_info.txt\", \"w\") as f:\n",
    "        f.write(f\"Dataset shape: {df.shape}\\n\")\n",
    "        f.write(f\"Class balance: {np.bincount(y_train_en)}\\n\")\n",
    "        f.write(f\"Scale pos weight: {scale_pos_weight}\\n\")\n",
    "    \n",
    "    return (X_train, X_val, X_test, y_train_en, y_val_en, y_test_en, \n",
    "            categorical_variables, numeric_variables, ohe, scaler, le, scale_pos_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2211d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(model_class, model_name, param_grid, X_train, y_train_en, X_val, y_val_en, X_test, y_test_en, \n",
    "                        num_vars, scale_pos_weight, ohe, scaler, le):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log preprocessing params (shared across models)\n",
    "        mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "        mlflow.log_param(\"cat_vars_count\", len(cat_vars))\n",
    "        mlflow.log_param(\"num_vars_count\", len(num_vars))\n",
    "        \n",
    "        # Initialize base model\n",
    "        if model_class == xgb.XGBClassifier:\n",
    "            base_model = model_class(objective='binary:logistic', scale_pos_weight=scale_pos_weight, \n",
    "                                     random_state=42, eval_metric='aucpr')\n",
    "        else:\n",
    "            base_model = model_class(random_state=42)\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train_en)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Log hyperparams\n",
    "        for param, value in best_params.items():\n",
    "            mlflow.log_param(f\"{model_name}_{param}\", value)\n",
    "        \n",
    "        # Predictions and metrics\n",
    "        y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "        y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        \n",
    "        val_auc = roc_auc_score(y_val_en, y_val_pred_proba)\n",
    "        test_auc = roc_auc_score(y_test_en, y_test_pred_proba)\n",
    "        \n",
    "        # Compute recall and precision for positive class (churn = 1)\n",
    "        test_recall = recall_score(y_test_en, y_test_pred, pos_label=1)\n",
    "        test_precision = precision_score(y_test_en, y_test_pred, pos_label=1)\n",
    "        \n",
    "        mlflow.log_metric(\"val_auc_roc\", val_auc)\n",
    "        mlflow.log_metric(\"test_auc_roc\", test_auc)\n",
    "        mlflow.log_metric(\"test_recall\", test_recall)\n",
    "        mlflow.log_metric(\"test_precision\", test_precision)\n",
    "        \n",
    "        # Log classification report as artifact\n",
    "        report = classification_report(y_test_en, y_test_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv(\"classification_report.csv\")\n",
    "        mlflow.log_artifact(\"classification_report.csv\")\n",
    "        \n",
    "        # Log model\n",
    "        if model_class == xgb.XGBClassifier:\n",
    "            mlflow.xgboost.log_model(best_model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(best_model, \"model\")\n",
    "        \n",
    "        # Log model details\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_param(\"target_encoder_classes\", list(le.classes_))\n",
    "        \n",
    "        print(f\"{model_name} Test AUC-ROC: {test_auc:.3f}, Recall: {test_recall:.3f}, Precision: {test_precision:.3f}\")\n",
    "        return best_model, test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437594e6",
   "metadata": {},
   "source": [
    "# workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15012eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = preprocess_data('../data/customer_churn_telecom_services.csv')\n",
    "(X_train, X_val, X_test, y_train_en, y_val_en, y_test_en, \n",
    " cat_vars, num_vars, ohe, scaler, le, scale_pos_weight) = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "020780eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three models to be trained (XGBoost, RandomForest, LogisticRegression)\n",
    "\n",
    "models = [\n",
    "    (\n",
    "        \"XGBoost\",\n",
    "        xgb.XGBClassifier(n_estimators = 100, max_depth = 3, learning_rate = 0.1),\n",
    "        (X_train, y_train_en),\n",
    "        (X_test, y_test_en)\n",
    "    ),\n",
    "    (\n",
    "        'randomforest', \n",
    "        RandomForestClassifier(n_estimators = 100, max_depth = 10),\n",
    "        (X_train, y_train_en),\n",
    "        (X_test, y_test_en)\n",
    "    ),\n",
    "    (\n",
    "        'LogisticRegression',\n",
    "        LogisticRegression(C = 1, penalty = 'l1', solver = 'liblinear'),\n",
    "        (X_train, y_train_en),\n",
    "        (X_test, y_test_en)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b92b35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train_en = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test_en = test_set[1]\n",
    "\n",
    "    model.fit(X_train, y_train_en)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test_en, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c951aabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.8462946020128088,\n",
       "  'recall': 0.893719806763285,\n",
       "  'f1-score': 0.8693609022556391,\n",
       "  'support': 1035.0},\n",
       " '1': {'precision': 0.6518987341772152,\n",
       "  'recall': 0.5508021390374331,\n",
       "  'f1-score': 0.5971014492753624,\n",
       "  'support': 374.0},\n",
       " 'accuracy': 0.8026969481902059,\n",
       " 'macro avg': {'precision': 0.749096668095012,\n",
       "  'recall': 0.7222609729003591,\n",
       "  'f1-score': 0.7332311757655008,\n",
       "  'support': 1409.0},\n",
       " 'weighted avg': {'precision': 0.7946948471721331,\n",
       "  'recall': 0.8026969481902059,\n",
       "  'f1-score': 0.7970933114716621,\n",
       "  'support': 1409.0}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83b62ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/25 13:02:54 INFO mlflow.tracking.fluent: Experiment with name 'Churn detection' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"Churn detection\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaaa3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/25 13:03:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/Users/daniel/anaconda3/envs/telco_churn/lib/python3.11/site-packages/xgboost/sklearn.py:1028: UserWarning: [13:03:00] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/10/25 13:03:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/10/25 13:03:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBoost at: http://127.0.0.1:5000/#/experiments/469149532379613833/runs/15be5651ad4e4752b38d2166482f254e\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/469149532379613833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/25 13:03:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/10/25 13:03:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run randomforest at: http://127.0.0.1:5000/#/experiments/469149532379613833/runs/8d9b3030043744f2bc7c4e56c55e4eaf\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/469149532379613833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/10/25 13:03:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run LogisticRegression at: http://127.0.0.1:5000/#/experiments/469149532379613833/runs/1ad7e518e1834c94817ca0728d032789\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/469149532379613833\n"
     ]
    }
   ],
   "source": [
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = reports[i]\n",
    "\n",
    "    with mlflow.start_run(run_name = model_name):\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric('accuracy', report['accuracy'])\n",
    "        mlflow.log_metric('recall_class_1', report['1']['recall'])\n",
    "        mlflow.log_metric('precision_class_1', report['1']['precision'])\n",
    "        mlflow.log_metric('recall_class_0', report['0']['recall'])\n",
    "        mlflow.log_metric('precision_class_0', report['0']['precision'])\n",
    "        mlflow.log_metric('f1_score_macro', report['macro avg']['f1-score']) \n",
    "\n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, f'{model_name} model')\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, f'{model_name} model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6a2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telco_churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
