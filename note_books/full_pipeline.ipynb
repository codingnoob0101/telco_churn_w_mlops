{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc03ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 15:56:33 INFO mlflow.tracking.fluent: Experiment with name 'Telco Churn Multi-Model' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import mlflow.sklearn\n",
    "import mlflow.shap  # For SHAP logging\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set up MLflow\n",
    "mlflow.set_experiment(\"Telco Churn Multi-Model\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5001\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855d268",
   "metadata": {},
   "source": [
    "# utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "437b6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    this function preprocess the data by taking in the original file path\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Fill missing in TotalCharges\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')  # Ensure numeric\n",
    "    df['TotalCharges'] = df['TotalCharges'].fillna(df['MonthlyCharges'] * df['tenure'])\n",
    "    \n",
    "    categorical_variables = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', \n",
    "                             'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                             'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n",
    "                             'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "    numeric_variables = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "    \n",
    "    variables = df[categorical_variables + numeric_variables]\n",
    "    target = df['Churn']\n",
    "    \n",
    "    # Train-val-test split\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        variables, target, test_size=0.2, random_state=42, stratify=target\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    "    )\n",
    "    \n",
    "    # Label encode target\n",
    "    le = LabelEncoder()\n",
    "    y_train_en = le.fit_transform(y_train)\n",
    "    y_val_en = le.transform(y_val)\n",
    "    y_test_en = le.transform(y_test)\n",
    "    \n",
    "    # One-hot encode categoricals\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
    "    X_train_ohe = pd.DataFrame(\n",
    "        ohe.fit_transform(X_train[categorical_variables]).toarray(), \n",
    "        columns=ohe.get_feature_names_out(), index=X_train.index\n",
    "    )\n",
    "    X_val_ohe = pd.DataFrame(\n",
    "        ohe.transform(X_val[categorical_variables]).toarray(), \n",
    "        columns=ohe.get_feature_names_out(), index=X_val.index\n",
    "    )\n",
    "    X_test_ohe = pd.DataFrame(\n",
    "        ohe.transform(X_test[categorical_variables]).toarray(), \n",
    "        columns=ohe.get_feature_names_out(), index=X_test.index\n",
    "    )\n",
    "    \n",
    "    # Combine numeric and encoded\n",
    "    X_train = pd.concat([X_train[numeric_variables], X_train_ohe], axis=1)\n",
    "    X_val = pd.concat([X_val[numeric_variables], X_val_ohe], axis=1)\n",
    "    X_test = pd.concat([X_test[numeric_variables], X_test_ohe], axis=1)\n",
    "    \n",
    "    # Scale numerics\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numeric_variables] = scaler.fit_transform(X_train[numeric_variables])\n",
    "    X_val[numeric_variables] = scaler.transform(X_val[numeric_variables])\n",
    "    X_test[numeric_variables] = scaler.transform(X_test[numeric_variables])\n",
    "    \n",
    "    # Imbalance handling: Compute scale_pos_weight\n",
    "    scale_pos_weight = sum(y_train_en == 0) / sum(y_train_en == 1)\n",
    "    \n",
    "    # Log data info as artifact\n",
    "    with open(\"data_info.txt\", \"w\") as f:\n",
    "        f.write(f\"Dataset shape: {df.shape}\\n\")\n",
    "        f.write(f\"Class balance: {np.bincount(y_train_en)}\\n\")\n",
    "        f.write(f\"Scale pos weight: {scale_pos_weight}\\n\")\n",
    "    \n",
    "    return (X_train, X_val, X_test, y_train_en, y_val_en, y_test_en, \n",
    "            categorical_variables, numeric_variables, ohe, scaler, le, scale_pos_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2211d973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model(model_class, model_name, param_grid, X_train, y_train_en, X_val, y_val_en, X_test, y_test_en, \n",
    "                        num_vars, scale_pos_weight, ohe, scaler, le):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log preprocessing params (shared across models)\n",
    "        mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "        mlflow.log_param(\"num_features\", X_train.shape[1])\n",
    "        mlflow.log_param(\"cat_vars_count\", len(cat_vars))\n",
    "        mlflow.log_param(\"num_vars_count\", len(num_vars))\n",
    "        \n",
    "        # Initialize base model\n",
    "        if model_class == xgb.XGBClassifier:\n",
    "            base_model = model_class(objective='binary:logistic', scale_pos_weight=scale_pos_weight, \n",
    "                                     random_state=42, eval_metric='aucpr')\n",
    "        else:\n",
    "            base_model = model_class(random_state=42)\n",
    "        \n",
    "        # Grid search\n",
    "        grid_search = GridSearchCV(base_model, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train_en)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Log hyperparams\n",
    "        for param, value in best_params.items():\n",
    "            mlflow.log_param(f\"{model_name}_{param}\", value)\n",
    "        \n",
    "        # Predictions and metrics\n",
    "        y_val_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "        y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        \n",
    "        val_auc = roc_auc_score(y_val_en, y_val_pred_proba)\n",
    "        test_auc = roc_auc_score(y_test_en, y_test_pred_proba)\n",
    "        \n",
    "        mlflow.log_metric(\"val_auc_roc\", val_auc)\n",
    "        mlflow.log_metric(\"test_auc_roc\", test_auc)\n",
    "        \n",
    "        # Log classification report as artifact\n",
    "        report = classification_report(y_test_en, y_test_pred, output_dict=True)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv(\"classification_report.csv\")\n",
    "        mlflow.log_artifact(\"classification_report.csv\")\n",
    "        \n",
    "        # Log model\n",
    "        if model_class == xgb.XGBClassifier:\n",
    "            mlflow.xgboost.log_model(best_model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(best_model, \"model\")\n",
    "        \n",
    "        # Log model details\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_param(\"target_encoder_classes\", list(le.classes_))\n",
    "        \n",
    "        print(f\"{model_name} Test AUC-ROC: {test_auc:.3f}\")\n",
    "        return best_model, test_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437594e6",
   "metadata": {},
   "source": [
    "# workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15012eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = preprocess_data('../data/customer_churn_telecom_services.csv')\n",
    "(X_train, X_val, X_test, y_train_en, y_val_en, y_test_en, \n",
    " cat_vars, num_vars, ohe, scaler, le, scale_pos_weight) = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34ce857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 15:56:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "/Users/daniel/anaconda3/envs/telco_churn/lib/python3.11/site-packages/xgboost/sklearn.py:1028: UserWarning: [15:56:45] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/10/21 15:56:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test AUC-ROC: 0.839\n",
      "üèÉ View run XGBoost at: http://127.0.0.1:5001/#/experiments/387869399784757540/runs/c203d34ec0cf4acc871184228ad0b414\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/387869399784757540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 15:56:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/21 15:56:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Test AUC-ROC: 0.840\n",
      "üèÉ View run RandomForest at: http://127.0.0.1:5001/#/experiments/387869399784757540/runs/55f63e5f75174e68a77fad42663d5637\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/387869399784757540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/21 15:56:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/10/21 15:56:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Test AUC-ROC: 0.843\n",
      "üèÉ View run LogisticRegression at: http://127.0.0.1:5001/#/experiments/387869399784757540/runs/4d52b09cb8284993a449f887728cad5a\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/387869399784757540\n",
      "Training complete. Results: {'XGBoost': 0.8385414244749283, 'RandomForest': 0.8396832777906946, 'LogisticRegression': 0.8426438296003514}\n"
     ]
    }
   ],
   "source": [
    "# Your existing param grids (unchanged)\n",
    "xgb_params = {'n_estimators': [100, 200], 'max_depth': [3, 5], 'learning_rate': [0.1, 0.01]}\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
    "lr_params = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}\n",
    "\n",
    "# Your models dictionary (unchanged)\n",
    "models_dict = {\n",
    "    \"XGBoost\": (xgb.XGBClassifier, xgb_params),\n",
    "    \"RandomForest\": (RandomForestClassifier, rf_params),\n",
    "    \"LogisticRegression\": (LogisticRegression, lr_params)\n",
    "}\n",
    "\n",
    "# Train models (now SHAP-free)\n",
    "results = {}\n",
    "for model_name, (model_class, param_grid) in models_dict.items():\n",
    "    model, auc = train_and_log_model(model_class, model_name, param_grid, \n",
    "                                     X_train, y_train_en, X_val, y_val_en, \n",
    "                                     X_test, y_test_en, num_vars, scale_pos_weight, \n",
    "                                     ohe, scaler, le)\n",
    "    results[model_name] = auc\n",
    "\n",
    "print(\"Training complete. Results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6a2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "telco_churn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
